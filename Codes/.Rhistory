linear.based <- function(data.trainS4, data.testS4, classts,
tL = 2, n = 5, r = 2){
# Define control function for all voom.based classifiers
linearControl <- discreteControl(method = "repeatedcv", number = n, repeats = r,
tuneLength = tL)
print("Fitting PLDA")
set.seed(1510)
# PLDA
fit.PLDA <- classify(data = data.trainS4, method = "PLDA",
normalize = "deseq", ref = "D",
control = linearControl)
#Predicted class labels
pred.PLDA <- predict(fit.PLDA, data.testS4)
pred.PLDA <- relevel(pred.PLDA, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblPLDA <- table(Predicted = pred.PLDA, Actual = actual)
PLDA.cm <- confusionMatrix(tblPLDA, positive = "D")
print("Fitting PLDA2")
set.seed(1510)
# PLDA2
fit.PLDA2 <- classify(data = data.trainS4, method = "PLDA2",
normalize = "deseq", ref = "D",
control = linearControl)
#Predicted class labels
pred.PLDA2 <- predict(fit.PLDA2, data.testS4)
pred.PLDA2 <- relevel(pred.PLDA2, ref = "D")
tblPLDA2 <- table(Predicted = pred.PLDA2, Actual = actual)
PLDA2.cm <- confusionMatrix(tblPLDA2, positive = "D")
print("Fitting NBLDA")
set.seed(1510)
# NBLDA
fit.NBLDA <- classify(data = data.trainS4, method = "NBLDA",
normalize = "deseq", ref = "D",
control = linearControl)
#Predicted class labels
pred.NBLDA <- predict(fit.NBLDA, data.testS4)
pred.NBLDA <- relevel(pred.NBLDA, ref = "D")
tblNBLDA <- table(Predicted = pred.NBLDA, Actual = actual)
NBLDA.cm <- confusionMatrix(tblNBLDA, positive = "D")
print("Successfully accomplished linear-based methods")
return(list(PLDA.cm, PLDA2.cm, NBLDA.cm))
}
lin <- linear.based(data.trainS4, data.testS4, classts)
View(lin)
lin[[1]]
lin[[2]]
lin[[3]]
relevel(classts$condition, ref = "D")
printAvailableMethods()
#' @description Tests several sparse-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each sparse-based method
sparse.based <- function(data.trainS4, data.testS4, classts,
tL = 2, n = 5, r = 2){
# Define control function for all sparse.based classifiers
sparseControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting SDWD")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.sdwd <- classify(data = data.trainS4, method = "sdwd",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = sparseControl)
#Predicted class labels
pred.sdwd <- predict(fit.sdwd, data.testS4)
pred.sdwd <- relevel(pred.sdwd, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblsdwd <- table(Predicted = pred.sdwd, Actual = actual)
sdwd.cm <- confusionMatrix(tblsdwd, positive = "D")
print("Fitting sparseLDA")
set.seed(1510)
# Sparse linear discriminant analysis
fit.sparseLDA <- classify(data = data.trainS4, method = "sparseLDA",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = sparseControl)
#Predicted class labels
pred.sparseLDA <- predict(fit.sparseLDA, data.testS4)
pred.sparseLDA <- relevel(pred.sparseLDA, ref = "D")
tblsparseLDA <- table(Predicted = pred.sparseLDA, Actual = actual)
sparseLDA.cm <- confusionMatrix(tblsparseLDA, positive = "D")
print("Fitting SPLS")
set.seed(1510)
# Sparse partial least squares
fit.spls <- classify(data = data.trainS4, method = "spls",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = sparseControl)
#Predicted class labels
pred.spls <- predict(fit.spls, data.testS4)
pred.spls <- relevel(pred.spls, ref = "D")
tblspls <- table(Predicted = pred.spls, Actual = actual)
spls.cm <- confusionMatrix(tblspls, positive = "D")
print("Successfully accomplished sparse-based methods")
return(list(sdwd.cm, sparseLDA.cm, spls.cm))
}
sparse <- sparse.based(data.trainS4, data.testS4, classts)
printAvailableMethods()
#' @description Tests several NNet-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each NNet-based method
nnet.based <- function(data.trainS4, data.testS4, classts,
tL = 2, n = 2, r = 2){
# Define control function for all NNet.based classifiers
nnetControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting nnet")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.nnet <- classify(data = data.trainS4, method = "nnet",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.nnet <- predict(fit.nnet, data.testS4)
pred.nnet <- relevel(pred.nnet, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblnnet <- table(Predicted = pred.nnet, Actual = actual)
nnet.cm <- confusionMatrix(tblnnet, positive = "D")
print("Fitting mlp")
set.seed(1510)
# Sparse linear discriminant analysis
fit.mlp <- classify(data = data.trainS4, method = "mlp",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.mlp <- predict(fit.mlp, data.testS4)
pred.mlp <- relevel(pred.mlp, ref = "D")
tblmlp <- table(Predicted = pred.mlp, Actual = actual)
mlp.cm <- confusionMatrix(tblmlp, positive = "D")
print("Fitting mlpML")
set.seed(1510)
# Sparse partial least squares
fit.mlpML <- classify(data = data.trainS4, method = "mlpML",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.mlpML <- predict(fit.mlpML, data.testS4)
pred.mlpML <- relevel(pred.mlpML, ref = "D")
tblmlpML <- table(Predicted = pred.mlpML, Actual = actual)
mlpML.cm <- confusionMatrix(tblmlpML, positive = "D")
print("Fitting avNNet")
set.seed(1510)
# Sparse partial least squares
fit.avNNet <- classify(data = data.trainS4, method = "avNNet",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.avNNet <- predict(fit.avNNet, data.testS4)
pred.avNNet <- relevel(pred.avNNet, ref = "D")
tblavNNet <- table(Predicted = pred.avNNet, Actual = actual)
avNNet.cm <- confusionMatrix(tblavNNet, positive = "D")
print("Successfully accomplished NNet-based methods")
return(list(nnet.cm, mlp.cm, mlpML.cm, avNNet.cm))
}
# sparse <- sparse.based(data.trainS4, data.testS4, classts) # <-- too slow!!
net <- nnet.based(data.trainS4, data.testS4, classts)
warnings()
#' @description Tests several NNet-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each NNet-based method
nnet.based <- function(data.trainS4, data.testS4, classts,
tL = 2, n = 5, r = 2){
# Define control function for all NNet.based classifiers
nnetControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting nnet")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.nnet <- classify(data = data.trainS4, method = "nnet",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.nnet <- predict(fit.nnet, data.testS4)
pred.nnet <- relevel(pred.nnet, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblnnet <- table(Predicted = pred.nnet, Actual = actual)
nnet.cm <- confusionMatrix(tblnnet, positive = "D")
print("Fitting mlp")
set.seed(1510)
# Sparse linear discriminant analysis
fit.mlp <- classify(data = data.trainS4, method = "mlp",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.mlp <- predict(fit.mlp, data.testS4)
pred.mlp <- relevel(pred.mlp, ref = "D")
tblmlp <- table(Predicted = pred.mlp, Actual = actual)
mlp.cm <- confusionMatrix(tblmlp, positive = "D")
print("Fitting mlpML")
set.seed(1510)
# Sparse partial least squares
fit.mlpML <- classify(data = data.trainS4, method = "mlpML",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.mlpML <- predict(fit.mlpML, data.testS4)
pred.mlpML <- relevel(pred.mlpML, ref = "D")
tblmlpML <- table(Predicted = pred.mlpML, Actual = actual)
mlpML.cm <- confusionMatrix(tblmlpML, positive = "D")
print("Fitting avNNet")
set.seed(1510)
# Sparse partial least squares
fit.avNNet <- classify(data = data.trainS4, method = "avNNet",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.avNNet <- predict(fit.avNNet, data.testS4)
pred.avNNet <- relevel(pred.avNNet, ref = "D")
tblavNNet <- table(Predicted = pred.avNNet, Actual = actual)
avNNet.cm <- confusionMatrix(tblavNNet, positive = "D")
print("Successfully accomplished NNet-based methods")
return(list(nnet.cm, mlp.cm, mlpML.cm, avNNet.cm))
}
# sparse <- sparse.based(data.trainS4, data.testS4, classts) # <-- too slow!!
net <- nnet.based(data.trainS4, data.testS4, classts)
warnings()
#' @description Tests several NNet-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each NNet-based method
nnet.based <- function(data.trainS4, data.testS4, classts,
tL = 2, n = 2, r = 2){
# Define control function for all NNet.based classifiers
nnetControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting nnet")
# set.seed(1510)
# # Sparse Distance Weighted Discrimination
# fit.nnet <- classify(data = data.trainS4, method = "nnet",
#                      preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
#                      control = nnetControl)
#
# #Predicted class labels
# pred.nnet <- predict(fit.nnet, data.testS4)
# pred.nnet <- relevel(pred.nnet, ref = "D")
actual <- relevel(classts$condition, ref = "D")
#
# tblnnet <- table(Predicted = pred.nnet, Actual = actual)
# nnet.cm <- confusionMatrix(tblnnet, positive = "D")
nnet.cm=1
print("Fitting mlp")
set.seed(1510)
# Sparse linear discriminant analysis
fit.mlp <- classify(data = data.trainS4, method = "mlp",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.mlp <- predict(fit.mlp, data.testS4)
pred.mlp <- relevel(pred.mlp, ref = "D")
tblmlp <- table(Predicted = pred.mlp, Actual = actual)
mlp.cm <- confusionMatrix(tblmlp, positive = "D")
print("Fitting mlpML")
set.seed(1510)
# Sparse partial least squares
fit.mlpML <- classify(data = data.trainS4, method = "mlpML",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.mlpML <- predict(fit.mlpML, data.testS4)
pred.mlpML <- relevel(pred.mlpML, ref = "D")
tblmlpML <- table(Predicted = pred.mlpML, Actual = actual)
mlpML.cm <- confusionMatrix(tblmlpML, positive = "D")
print("Fitting avNNet")
set.seed(1510)
# Sparse partial least squares
fit.avNNet <- classify(data = data.trainS4, method = "avNNet",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.avNNet <- predict(fit.avNNet, data.testS4)
pred.avNNet <- relevel(pred.avNNet, ref = "D")
tblavNNet <- table(Predicted = pred.avNNet, Actual = actual)
avNNet.cm <- confusionMatrix(tblavNNet, positive = "D")
print("Successfully accomplished NNet-based methods")
return(list(nnet.cm, mlp.cm, mlpML.cm, avNNet.cm))
}
# sparse <- sparse.based(data.trainS4, data.testS4, classts) # <-- too slow!!
net <- nnet.based(data.trainS4, data.testS4, classts)
#' @description Tests several NNet-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each NNet-based method
nnet.based <- function(data.trainS4, data.testS4, classts,
tL = 2, n = 2, r = 2){
# Define control function for all NNet.based classifiers
nnetControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting nnet")
# set.seed(1510)
# # Sparse Distance Weighted Discrimination
# fit.nnet <- classify(data = data.trainS4, method = "nnet",
#                      preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
#                      control = nnetControl)
#
# #Predicted class labels
# pred.nnet <- predict(fit.nnet, data.testS4)
# pred.nnet <- relevel(pred.nnet, ref = "D")
actual <- relevel(classts$condition, ref = "D")
#
# tblnnet <- table(Predicted = pred.nnet, Actual = actual)
# nnet.cm <- confusionMatrix(tblnnet, positive = "D")
nnet.cm=1
print("Fitting mlp")
set.seed(1510)
# Sparse linear discriminant analysis
fit.mlp <- classify(data = data.trainS4, method = "mlp",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.mlp <- predict(fit.mlp, data.testS4)
pred.mlp <- relevel(pred.mlp, ref = "D")
tblmlp <- table(Predicted = pred.mlp, Actual = actual)
mlp.cm <- confusionMatrix(tblmlp, positive = "D")
print("Fitting mlpML")
set.seed(1510)
# Sparse partial least squares
fit.mlpML <- classify(data = data.trainS4, method = "mlpML",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.mlpML <- predict(fit.mlpML, data.testS4)
pred.mlpML <- relevel(pred.mlpML, ref = "D")
tblmlpML <- table(Predicted = pred.mlpML, Actual = actual)
mlpML.cm <- confusionMatrix(tblmlpML, positive = "D")
print("Fitting avNNet")
# set.seed(1510)
# # Sparse partial least squares
# fit.avNNet <- classify(data = data.trainS4, method = "avNNet",
#                       preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
#                       control = nnetControl)
#
# #Predicted class labels
# pred.avNNet <- predict(fit.avNNet, data.testS4)
# pred.avNNet <- relevel(pred.avNNet, ref = "D")
#
# tblavNNet <- table(Predicted = pred.avNNet, Actual = actual)
# avNNet.cm <- confusionMatrix(tblavNNet, positive = "D")
avNNet.cm = 1
print("Successfully accomplished NNet-based methods")
return(list(nnet.cm, mlp.cm, mlpML.cm, avNNet.cm))
}
# sparse <- sparse.based(data.trainS4, data.testS4, classts) # <-- too slow!!
net <- nnet.based(data.trainS4, data.testS4, classts)
View(net)
net[[2]]
net[[3]]
net[[3]]
printAvailableMethods()
#' @description Tests several tree-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each tree-based method
tree.based <- function(data.trainS4, data.testS4, classts,
tL = 2, n = 2, r = 2){
# Define control function for all NNet.based classifiers
treeControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting rpart")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.rpart <- classify(data = data.trainS4, method = "rpart",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
#Predicted class labels
pred.rpart <- predict(fit.rpart, data.testS4)
pred.rpart <- relevel(pred.rpart, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblrpart <- table(Predicted = pred.rpart, Actual = actual)
rpart.cm <- confusionMatrix(tblrpart, positive = "D")
print("Fitting cforest")
set.seed(1510)
# Sparse linear discriminant analysis
fit.cforest <- classify(data = data.trainS4, method = "cforest",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
#Predicted class labels
pred.cforest <- predict(fit.cforest, data.testS4)
pred.cforest <- relevel(pred.cforest, ref = "D")
tblcforest <- table(Predicted = pred.cforest, Actual = actual)
cforest.cm <- confusionMatrix(tblcforest, positive = "D")
print("Fitting ctree")
set.seed(1510)
# Sparse partial least squares
fit.ctree <- classify(data = data.trainS4, method = "ctree",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
#Predicted class labels
pred.ctree <- predict(fit.ctree, data.testS4)
pred.ctree <- relevel(pred.ctree, ref = "D")
tblctree <- table(Predicted = pred.ctree, Actual = actual)
ctree.cm <- confusionMatrix(tblctree, positive = "D")
print("Fitting rf")
set.seed(1510)
# Sparse partial least squares
fit.rf <- classify(data = data.trainS4, method = "rf",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
#Predicted class labels
pred.rf <- predict(fit.rf, data.testS4)
pred.rf <- relevel(pred.rf, ref = "D")
tblrf <- table(Predicted = pred.rf, Actual = actual)
rf.cm <- confusionMatrix(tblrf, positive = "D")
print("Successfully accomplished tree-based methods")
return(list(rpart.cm, cforest.cm, ctree.cm, rf.cm))
}
tree <- tree.based(data.trainS4, data.testS4, classts)
View(df)
df <- df[1:10000, ]
tts <- trainTest.split(df, class)
data.trainS4 <- tts[[1]]
data.testS4 <- tts[[2]]
classts <- tts[[3]]
tree <- tree.based(data.trainS4, data.testS4, classts)
View(tree)
tree[[1]]
tree[[2]]
tree[[3]]
tree[[4]]
options(expressions = 5e5)
?options
Cstack_info()
#' @description Tests several NNet-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each NNet-based method
nnet.based <- function(data.trainS4, data.testS4, classts,
tL = 2, n = 2, r = 2){
# Define control function for all NNet.based classifiers
nnetControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting nnet")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.nnet <- classify(data = data.trainS4, method = "nnet",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.nnet <- predict(fit.nnet, data.testS4)
pred.nnet <- relevel(pred.nnet, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblnnet <- table(Predicted = pred.nnet, Actual = actual)
nnet.cm <- confusionMatrix(tblnnet, positive = "D")
nnet.cm=1
print("Fitting mlp")
set.seed(1510)
# Sparse linear discriminant analysis
fit.mlp <- classify(data = data.trainS4, method = "mlp",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.mlp <- predict(fit.mlp, data.testS4)
pred.mlp <- relevel(pred.mlp, ref = "D")
tblmlp <- table(Predicted = pred.mlp, Actual = actual)
mlp.cm <- confusionMatrix(tblmlp, positive = "D")
print("Fitting mlpML")
set.seed(1510)
# Sparse partial least squares
fit.mlpML <- classify(data = data.trainS4, method = "mlpML",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.mlpML <- predict(fit.mlpML, data.testS4)
pred.mlpML <- relevel(pred.mlpML, ref = "D")
tblmlpML <- table(Predicted = pred.mlpML, Actual = actual)
mlpML.cm <- confusionMatrix(tblmlpML, positive = "D")
print("Fitting avNNet")
set.seed(1510)
# Sparse partial least squares
fit.avNNet <- classify(data = data.trainS4, method = "avNNet",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = nnetControl)
#Predicted class labels
pred.avNNet <- predict(fit.avNNet, data.testS4)
pred.avNNet <- relevel(pred.avNNet, ref = "D")
tblavNNet <- table(Predicted = pred.avNNet, Actual = actual)
avNNet.cm <- confusionMatrix(tblavNNet, positive = "D")
avNNet.cm = 1
print("Successfully accomplished NNet-based methods")
return(list(nnet.cm, mlp.cm, mlpML.cm, avNNet.cm))
}
# sparse <- sparse.based(data.trainS4, data.testS4, classts) # <-- too slow!!
net <- nnet.based(data.trainS4, data.testS4, classts)
options()
