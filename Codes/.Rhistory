set.seed(1510)
# Sparse linear discriminant analysis
fit.cforest <- classify(data = data.trainS4, method = "cforest",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
#Predicted class labels
pred.cforest <- predict(fit.cforest, data.testS4)
pred.cforest <- relevel(pred.cforest, ref = "D")
tblcforest <- table(Predicted = pred.cforest, Actual = actual)
cforest.cm <- confusionMatrix(tblcforest, positive = "D")
print("Fitting ctree")
set.seed(1510)
# Sparse partial least squares
fit.ctree <- classify(data = data.trainS4, method = "ctree",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
#Predicted class labels
pred.ctree <- predict(fit.ctree, data.testS4)
pred.ctree <- relevel(pred.ctree, ref = "D")
tblctree <- table(Predicted = pred.ctree, Actual = actual)
ctree.cm <- confusionMatrix(tblctree, positive = "D")
# fit.ctree@modelInfo@trainedModel[["finalModel"]]@tree
print("Fitting rf")
set.seed(1510)
# Sparse partial least squares
fit.rf <- classify(data = data.trainS4, method = "rf",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
#Predicted class labels
pred.rf <- predict(fit.rf, data.testS4)
pred.rf <- relevel(pred.rf, ref = "D")
tblrf <- table(Predicted = pred.rf, Actual = actual)
rf.cm <- confusionMatrix(tblrf, positive = "D")
# Compute elbow genes
coeff_rf <- as.data.frame(fit.rf@modelInfo@trainedModel[["finalModel"]][["importance"]])$MeanDecreaseGini
names(coeff_rf) <- rownames(as.data.frame(fit.rf@modelInfo@trainedModel[["finalModel"]][["importance"]]))
genes_rf_treeBased <- list(elbow_comp(coefficients = coeff_rf))
print("Successfully accomplished tree-based methods")
return(list(rpart.cm, cforest.cm, ctree.cm, rf.cm,
genes_rpart_treeBased, genes_rf_treeBased))
}
#' @description Tests several bagging-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each bagging-based method
bagg.based <- function(data.trainS4, data.testS4, classts,
tL = 2, n = 2, r = 2){
library(adabag)
library(earth)
# Define control function for all bagg.based classifiers
baggControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting AdaBag")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.AdaBag <- classify(data = data.trainS4, method = "AdaBag",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
#Predicted class labels
pred.AdaBag <- predict(fit.AdaBag, data.testS4)
pred.AdaBag <- relevel(pred.AdaBag, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblAdaBag <- table(Predicted = pred.AdaBag, Actual = actual)
AdaBag.cm <- confusionMatrix(tblAdaBag, positive = "D")
genes_AdaBag_baggedBased <- list(fit.AdaBag@modelInfo@trainedModel[["finalModel"]][["importance"]])
print("Fitting treebag")
set.seed(1510)
# Sparse linear discriminant analysis
fit.treebag <- classify(data = data.trainS4, method = "treebag",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
#Predicted class labels
pred.treebag <- predict(fit.treebag, data.testS4)
pred.treebag <- relevel(pred.treebag, ref = "D")
tbltreebag <- table(Predicted = pred.treebag, Actual = actual)
treebag.cm <- confusionMatrix(tbltreebag, positive = "D")
# fit.treebag@modelInfo@trainedModel[["finalModel"]][["mtrees"]]
print("Fitting bagFDA")
set.seed(1510)
# Sparse partial least squares
fit.bagFDA <- classify(data = data.trainS4, method = "bagFDA",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
#Predicted class labels
pred.bagFDA <- predict(fit.bagFDA, data.testS4)
pred.bagFDA <- relevel(pred.bagFDA, ref = "D")
tblbagFDA <- table(Predicted = pred.bagFDA, Actual = actual)
bagFDA.cm <- confusionMatrix(tblbagFDA, positive = "D")
print("Successfully accomplished bagging-based methods")
return(list(AdaBag.cm, treebag.cm, bagFDA.cm,
genes_AdaBag_baggedBased))
}
#' @description Tests several boost-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each boost-based method
boost.based <- function(data.trainS4, data.testS4, classts,
tL = 2, n = 2, r = 2){
# Define control function for all boost.based classifiers
boostControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting gamboost")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.gamboost <- classify(data = data.trainS4, method = "gamboost",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = boostControl)
#Predicted class labels
pred.gamboost <- predict(fit.gamboost, data.testS4)
pred.gamboost <- relevel(pred.gamboost, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblgamboost <- table(Predicted = pred.gamboost, Actual = actual)
gamboost.cm <- confusionMatrix(tblgamboost, positive = "D")
genes_gamboost_boostBased <- list(names(coef(fit.gamboost@modelInfo@trainedModel[["finalModel"]])))
print("Fitting bstSm")
set.seed(1510)
# Sparse linear discriminant analysis
fit.bstSm <- classify(data = data.trainS4, method = "bstSm",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = boostControl)
#Predicted class labels
pred.bstSm <- predict(fit.bstSm, data.testS4)
pred.bstSm <- relevel(pred.bstSm, ref = "D")
tblbstSm <- table(Predicted = pred.bstSm, Actual = actual)
bstSm.cm <- confusionMatrix(tblbstSm, positive = "D")
genes_bstSm_boostBased <- list(fit.bstSm@modelInfo@trainedModel[["finalModel"]][["xNames"]][c(fit.bstSm@modelInfo@trainedModel[["finalModel"]][["xselect"]])])
print("Fitting bstTree")
set.seed(1510)
# Sparse partial least squares
fit.bstTree <- classify(data = data.trainS4, method = "bstTree",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = boostControl)
#Predicted class labels
pred.bstTree <- predict(fit.bstTree, data.testS4)
pred.bstTree <- relevel(pred.bstTree, ref = "D")
tblbstTree <- table(Predicted = pred.bstTree, Actual = actual)
bstTree.cm <- confusionMatrix(tblbstTree, positive = "D")
genes_bstTree_boostBased <- list(fit.bstTree@modelInfo@trainedModel[["finalModel"]][["xNames"]][c(fit.bstTree@modelInfo@trainedModel[["finalModel"]][["xselect"]])])
print("Successfully accomplished boost-based methods")
return(list(gamboost.cm, bstSm.cm, bstTree.cm,
genes_gamboost_boostBased, genes_bstSm_boostBased, genes_bstTree_boostBased))
}
#' @description Tests several pls-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each pls-based method
pls.based <- function(data.trainS4, data.testS4, classts,
tL = 20, n = 2, r = 2){
library(gpls)
# Define control function for all sparse.based classifiers
plsControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting gpls")
set.seed(1510)
# generalized partial least squares
fit.gpls <- classify(data = data.trainS4, method = "gpls",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = plsControl)
#Predicted class labels
pred.gpls <- predict(fit.gpls, data.testS4)
pred.gpls <- relevel(pred.gpls, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblgpls <- table(Predicted = pred.gpls, Actual = actual)
gpls.cm <- confusionMatrix(tblgpls, positive = "D")
# compute elbow genes
coeff_gpls <- abs(fit.gpls@modelInfo@trainedModel[["finalModel"]][["coefficients"]][-1])
genes_gpls_plsBased <- list(elbow_comp(coefficients = coeff_gpls))
print("Fitting pls")
set.seed(1510)
# partial least squares
fit.pls <- classify(data = data.trainS4, method = "pls",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = plsControl)
#Predicted class labels
pred.pls <- predict(fit.pls, data.testS4)
pred.pls <- relevel(pred.pls, ref = "D")
tblpls <- table(Predicted = pred.pls, Actual = actual)
pls.cm <- confusionMatrix(tblpls, positive = "D")
# compute elbow genes
coeff_pls <- abs(fit.pls@modelInfo@trainedModel[["finalModel"]][["coefficients"]][,1,])
genes_pls_plsBased <- list(elbow_comp(coefficients = coeff_pls))
print("Fitting SPLS")
set.seed(1510)
# Sparse partial least squares
fit.spls <- classify(data = data.trainS4, method = "spls",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = plsControl)
#Predicted class labels
pred.spls <- predict(fit.spls, data.testS4)
pred.spls <- relevel(pred.spls, ref = "D")
tblspls <- table(Predicted = pred.spls, Actual = actual)
spls.cm <- confusionMatrix(tblspls, positive = "D")
# compute elbow genes
coeff_spls <- abs(fit.spls@modelInfo@trainedModel[["finalModel"]][["normx"]])
genes_spls_plsBased <- list(elbow_comp(coefficients = coeff_spls))
print("Successfully accomplished pls-based methods")
return(list(gpls.cm, pls.cm, spls.cm,
genes_gpls_plsBased, genes_pls_plsBased, genes_spls_plsBased))
}
dfsImport <- dfs.import()
df <- dfsImport[[1]]
#df <- df[1:1500, ]
class <- dfsImport[[2]]
keep <- rowSums(df > 10) > round(ncol(df)/3)
df <- df[keep, ]
seed=123
mincorr = 0.4
tts <- trainTest.split(df, class, mincorr = mincorr, seed = seed)
data.trainS4 <- tts[[1]]
data.testS4 <- tts[[2]]
classts <- tts[[3]]
# mini-check per vedere se i geni filtati sono gli stessi
sum(rownames(assay(data.trainS4)) == rownames(assay(data.testS4)))
tL = 10
n = 5
r = 2
# Define control function for all svm.based classifiers
svmControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting SVM-Radial")
set.seed(1510)
# Support vector machines with radial basis function kernel
fit.svmRadial <- classify(data = data.trainS4, method = "svmRadial",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = svmControl)
# Compute elbow genes
coeff_svmRadial <- varImp(fit.svmRadial@modelInfo@trainedModel)[["importance"]]$D
names(coeff_svmRadial) <- rownames(varImp(fit.svmRadial@modelInfo@trainedModel)[["importance"]])
genes_svmRadial_SVMBased <- list(elbow_comp(coefficients = coeff_svmRadial))
View(genes_svmRadial_SVMBased)
print("Fitting SVM-Poly")
set.seed(1510)
# Support vector machines with poly basis function kernel
fit.svmPoly <- classify(data = data.trainS4, method = "svmPoly",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = svmControl)
# Compute elbow genes
coeff_svmPoly <- varImp(fit.svmPoly@modelInfo@trainedModel)[["importance"]]$D
names(coeff_svmPoly) <- rownames(varImp(fit.svmPoly@modelInfo@trainedModel)[["importance"]])
genes_svmPoly_SVMBased <- list(elbow_comp(coefficients = coeff_svmPoly))
View(genes_svmPoly_SVMBased)
View(genes_svmRadial_SVMBased)
genes_svmRadial_SVMBased[[1]]
genes_svmPoly_SVMBased[[1]]
print("Fitting SVM-Linear")
set.seed(1510)
# Support vector machines with linear basis function kernel
fit.svmLinear <- classify(data = data.trainS4, method = "svmLinear",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = svmControl)
# Compute elbow genes
coeff_svmLinear <- varImp(fit.svmLinear@modelInfo@trainedModel)[["importance"]]$D
names(coeff_svmLinear) <- rownames(varImp(fit.svmLinear@modelInfo@trainedModel)[["importance"]])
genes_svmLinear_SVMBased <- list(elbow_comp(coefficients = coeff_svmLinear))
View(genes_svmLinear_SVMBased)
genes_svmLinear_SVMBased[[1]]
# Define control function for all voom.based classifiers
voomControl <- voomControl(method = "repeatedcv", number = n, repeats = r,
tuneLength = tL)
print("Fitting voom-DLDA")
set.seed(1510)
# voomDLDA
fit.voomDLDA <- classify(data = data.trainS4, method = "voomDLDA",
normalize = "deseq", ref = "D",
control = voomControl)
View(fit.voomDLDA)
varImp(fit.voomDLDA@modelInfo@trainedModel@finalModel)
varImp(fit.voomDLDA@modelInfo@trainedModel)
# Compute elbow genes
coeff_voomDLDA <- fit.voomDLDA@modelInfo@trainedModel@finalModel[["model"]][["weightedStats"]][["weightedMean"]]
names(coeff_voomDLDA) <- rownames(fit.voomDLDA@modelInfo@trainedModel@finalModel[["model"]][["weightedStats"]][["weightedMean.C"]])
genes_voomDLDA_voomBased <- list(elbow_comp(coefficients = coeff_voomDLDA))
print("Fitting voom-DQDA")
set.seed(123)
# voomDQDA
fit.voomDQDA <- classify(data = data.trainS4, method = "voomDQDA",
normalize = "deseq", ref = "D",
control = voomControl)
# Compute elbow genes
coeff_voomDQDA <- fit.voomDQDA@modelInfo@trainedModel@finalModel[["model"]][["weightedStats"]][["weightedMean"]]
names(coeff_voomDQDA) <- rownames(fit.voomDQDA@modelInfo@trainedModel@finalModel[["model"]][["weightedStats"]][["weightedMean.C"]])
genes_voomDQDA_voomBased <- list(elbow_comp(coefficients = coeff_voomDQDA))
print("Fitting voom-NSC")
set.seed(1510)
# voomNSC
fit.voomNSC <- classify(data = data.trainS4, method = "voomNSC",
normalize = "deseq", ref = "D",
control = voomControl)
# Compute elbow genes
coeff_voomNSC <- fit.voomNSC@modelInfo@trainedModel@finalModel[["model"]][["weightedMean"]]
names(coeff_voomNSC) <- rownames(fit.voomNSC@modelInfo@trainedModel@finalModel[["model"]][["weightedMean.C"]])
genes_voomNSC_voomBased <- list(elbow_comp(coefficients = coeff_voomNSC))
# Define control function for all voom.based classifiers
linearControl <- discreteControl(method = "repeatedcv", number = n, repeats = r,
tuneLength = tL)
print("Fitting PLDA")
set.seed(1510)
# PLDA
fit.PLDA <- classify(data = data.trainS4, method = "PLDA",
normalize = "deseq", ref = "D",
control = linearControl)
genes_PLDA_LDABased <- list(selectedGenes(fit.PLDA))
View(genes_PLDA_LDABased)
print("Fitting PLDA2")
set.seed(1510)
# PLDA2
fit.PLDA2 <- classify(data = data.trainS4, method = "PLDA2",
normalize = "deseq", ref = "D",
control = linearControl)
genes_PLDA2_LDABased <- list(selectedGenes(fit.PLDA2))
View(fit.PLDA2)
View(genes_PLDA2_LDABased)
print("Fitting NBLDA")
set.seed(1510)
# NBLDA
fit.NBLDA <- classify(data = data.trainS4, method = "NBLDA",
normalize = "deseq", ref = "D",
control = linearControl)
genes_NBLDA_LDABased <- list(selectedGenes(fit.NBLDA))
View(genes_NBLDA_LDABased)
View(fit.NBLDA)
varImp(fit.NBLDA@modelInfo@trainedModel@finalModel)
# Define control function for all sparse.based classifiers
sparseControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting sparseLDA")
set.seed(1510)
# Sparse linear discriminant analysis
fit.sparseLDA <- classify(data = data.trainS4, method = "sparseLDA",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = sparseControl)
View(fit.sparseLDA)
varImp(fit.sparseLDA@modelInfo@trainedModel[["finalModel"]])
varImp(fit.sparseLDA@modelInfo@trainedModel)
# Compute elbow genes
coeff_sparseLDA <- varImp(fit.sparseLDA@modelInfo@trainedModel)[["importance"]]$D
genes_sparseLDA_LDAbased <- list(genes_sparseLDA_LDAbased = fit.sparseLDA@modelInfo@trainedModel[["finalModel"]][["varNames"]])
# Compute important genes
# coeff_svmPoly <- varImp(fit.svmPoly@modelInfo@trainedModel)[["importance"]]$D
# names(coeff_svmPoly) <- rownames(varImp(fit.svmPoly@modelInfo@trainedModel)[["importance"]])
# genes_svmPoly_SVMBased <- list(elbow_comp(coefficients = coeff_svmPoly))
genes_svmPoly_SVMBased <- list(colnames(fit.svmPoly@modelInfo@trainedModel$trainingData[, c(fit.svmPoly@modelInfo@trainedModel$finalModel@SVindex)]))
View(genes_svmPoly_SVMBased)
# Compute important genes
# coeff_svmPoly <- varImp(fit.svmPoly@modelInfo@trainedModel)[["importance"]]$D
# names(coeff_svmPoly) <- rownames(varImp(fit.svmPoly@modelInfo@trainedModel)[["importance"]])
# genes_svmPoly_SVMBased <- list(elbow_comp(coefficients = coeff_svmPoly))
genes_svmPoly_SVMBased <- list(colnames(fit.svmPoly@modelInfo@trainedModel$trainingData[, c(fit.svmPoly@modelInfo@trainedModel$finalModel@SVindex)]))
View(genes_svmPoly_SVMBased)
View(genes_svmLinear_SVMBased)
# Compute important genes
# coeff_svmLinear <- varImp(fit.svmLinear@modelInfo@trainedModel)[["importance"]]$D
# names(coeff_svmLinear) <- rownames(varImp(fit.svmLinear@modelInfo@trainedModel)[["importance"]])
# genes_svmLinear_SVMBased <- list(elbow_comp(coefficients = coeff_svmLinear))
genes_svmLinear_SVMBased <- list(colnames(fit.svmLinear@modelInfo@trainedModel$trainingData[, c(fit.svmLinear@modelInfo@trainedModel$finalModel@SVindex)]))
View(genes_svmLinear_SVMBased)
# Compute important genes
# coeff_svmRadial <- varImp(fit.svmRadial@modelInfo@trainedModel)[["importance"]]$D
# names(coeff_svmRadial) <- rownames(varImp(fit.svmRadial@modelInfo@trainedModel)[["importance"]])
# genes_svmRadial_SVMBased <- list(elbow_comp(coefficients = coeff_svmRadial))
genes_svmRadial_SVMBased <- list(colnames(fit.svmRadial@modelInfo@trainedModel$trainingData[, c(fit.svmRadial@modelInfo@trainedModel$finalModel@SVindex)]))
View(genes_svmRadial_SVMBased)
View(genes_svmPoly_SVMBased)
View(genes_svmLinear_SVMBased)
# Define control function for all NNet.based classifiers
treeControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE,
savePredictions = "all", returnData = T)
print("Fitting rpart")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.rpart <- classify(data = data.trainS4, method = "rpart",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
genes_rpart_treeBased <- list(fit.rpart@modelInfo@trainedModel[["finalModel"]][["variable.importance"]])
View(genes_rpart_treeBased)
genes_rpart_treeBased[[1]]
print("Fitting cforest")
set.seed(1510)
# Sparse linear discriminant analysis
fit.cforest <- classify(data = data.trainS4, method = "cforest",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
View(fit.cforest)
varImp(fit.cforest@modelInfo@trainedModel[["finalModel"]])
a <- varImp(fit.cforest@modelInfo@trainedModel[["finalModel"]])
View(a)
# Compute elbow genes
coeff_cforest <- varImp(fit.cforest@modelInfo@trainedModel[["finalModel"]])$Overall
names(coeff_cforest) <- rownames(varImp(fit.cforest@modelInfo@trainedModel[["finalModel"]]))
genes_cforest_treeBased <- list(elbow_comp(coefficients = coeff_cforest))
View(genes_cforest_treeBased)
genes_cforest_treeBased[[1]]
print("Fitting ctree")
set.seed(1510)
# Sparse partial least squares
fit.ctree <- classify(data = data.trainS4, method = "ctree",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
varImp(fit.ctree@modelInfo@trainedModel[["finalModel"]])
varImp(fit.ctree@modelInfo@trainedModel)
varImp(fit.ctree@modelInfo@trainedModel) == varImp(fit.cforest@modelInfo@trainedModel)
a <- varImp(fit.ctree@modelInfo@trainedModel)
b <- varImp(fit.cforest@modelInfo@trainedModel)
View(a)
View(a[["importance"]])
View(b)
View(b[["importance"]])
# compute elbow genes
coeff_ctree <- varImp(fit.ctree@modelInfo@trainedModel)[["importance"]]
View(coeff_ctree)
# compute elbow genes
coeff_ctree <- varImp(fit.ctree@modelInfo@trainedModel)[["importance"]]$D
names(coeff_ctree) <- rownames(varImp(fit.ctree@modelInfo@trainedModel)[["importance"]])
coeff_ctree
genes_ctree_treeBased <- list(elbow_comp(coefficients = coeff_ctree))
View(genes_cforest_treeBased)
View(genes_ctree_treeBased)
genes_ctree_treeBased[[1]] %in% genes_cforest_treeBased[[1]]
# Define control function for all bagg.based classifiers
baggControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting AdaBag")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.AdaBag <- classify(data = data.trainS4, method = "AdaBag",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
tL = 2
n = 2
r = 2
print("Fitting treebag")
set.seed(1510)
# Sparse linear discriminant analysis
fit.treebag <- classify(data = data.trainS4, method = "treebag",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
View(fit.treebag)
varImp(fit.treebag@modelInfo@trainedModel[["finalModel"]])
a <- varImp(fit.treebag@modelInfo@trainedModel[["finalModel"]])
View(a)
# Compute elbow genes
coeff_treebag <- varImp(fit.treebag@modelInfo@trainedModel[["finalModel"]])$Overall
names(coeff_treebag) <- rownames(varImp(fit.treebag@modelInfo@trainedModel[["finalModel"]]))
genes_treebag_baggedBased <- list(elbow_comp(coefficients = coeff_treebag))
View(genes_treebag_baggedBased)
genes_treebag_baggedBased[[1]]
View(genes_rpart_treeBased)
View(genes_cforest_treeBased)
genes_cforest_treeBased[[1]]
print("Fitting bagFDA")
set.seed(1510)
# Sparse partial least squares
fit.bagFDA <- classify(data = data.trainS4, method = "bagFDA",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
View(fit.bagFDA)
varImp(fit.bagFDA@modelInfo@trainedModel[["finalModel"]])
varImp(fit.bagFDA@modelInfo@trainedModel)
tL = 10
print("Fitting bagFDA")
set.seed(1510)
# Sparse partial least squares
fit.bagFDA <- classify(data = data.trainS4, method = "bagFDA",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
View(fit.bagFDA)
varImp(fit.bagFDA@modelInfo@trainedModel[["finalModel"]])
varImp(fit.bagFDA@modelInfo@trainedModel)
fit.bagFDA@modelInfo@trainedModel[["finalModel"]][["x"]]
varImp(fit.bagFDA@modelInfo@trainedModel)
library(caret)
varImp(fit.bagFDA@modelInfo@trainedModel)
a <- fit.bagFDA
View(a)
varImp(a@modelInfo@trainedModel[["finalModel"]])
a@modelInfo@trainedModel[["results"]]
View(a@modelInfo@trainedModel[["results"]])
a@modelInfo@trainedModel[["modelInfo"]][["varImp"]]
a@modelInfo@trainedModel[["modelInfo"]]$varImp()
a@modelInfo@trainedModel[["modelInfo"]]$varImp
a@modelInfo@trainedModel[["modelInfo"]]$varImp()
View(a@modelInfo@trainedModel[["modelInfo"]][["varImp"]])
varImp(fit.bagFDA@modelInfo@trainedModel[["modelInfo"]])
varImp(fit.bagFDA@modelInfo@trainedModel)
varImp
varImp(fit.bagFDA@modelInfo@trainedModel[["finalModel"]][["x"]])
fit.bagFDA@modelInfo@trainedModel[["finalModel"]][["xNames"]]
# Define control function for all bagg.based classifiers
baggControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE,
savePredictions = "all", returnData = T)
# Sparse partial least squares
fit.bagFDA <- classify(data = data.trainS4, method = "bagFDA",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
View(fit.bagFDA)
varImp(fit.bagFDA@modelInfo@trainedModel[["finalModel"]])
varImp(fit.bagFDA@modelInfo@trainedModel)
fit.bagFDA@modelInfo@trainedModel$varImp()
