actives_pred <- 1:5
View(Sigma)
## ----X------------------------------------------------------------------------
X_bm <- MASS::mvrnorm(n = n, mu=rep(0,p), Sigma, tol = 1e-6, empirical = FALSE)
colnames(X_bm) <- paste0("X",(1:p))
n1=n2=n/2 # 1:1 randomized
beta1 <- rep(0,p)
beta1[actives] <- 1
beta2 <- beta1
beta2[actives_pred] <- 2
beta <- c(beta1, beta2)
TRT1 <- c(rep(1,n1), rep(0,n2))
TRT2 <- c(rep(0,n1), rep(1,n2))
Y <- cbind(X_bm*TRT1,X_bm*TRT2)%*%beta+TRT2+rnorm(n,0,1)
View(X_bm)
View(Y)
## ----est Sigma----------------------------------------------------------------
cv_cov_est_out <- cvCovEst(
dat = X_bm,
estimators = c(
linearShrinkLWEst, denseLinearShrinkEst,
thresholdingEst, poetEst, sampleCovEst
),
estimator_params = list(
thresholdingEst = list(gamma = c(0.2, 0.4)),
poetEst = list(lambda = c(0.1, 0.2), k = c(1L, 2L))
),
cv_loss = cvMatrixFrobeniusLoss,
cv_scheme = "v_fold",
v_folds = 5
)
View(cv_cov_est_out)
Sigma_est <- cov2cor(cv_cov_est_out$estimate)
View(Sigma_est)
View(X_bm)
View(Y)
TRT1
TRT2
beta1
beta2
beta
## ----WLasso model, warning = FALSE, message = FALSE---------------------------
mod <- ProgPredLasso(X1 = X_bm[1:n1, ], X2 = X_bm[(n1+1):n, ], Y = Y, cor_matrix = Sigma_est)
View(mod)
mod[["beta"]]
## -----------------------------------------------------------------------------
#alpha1
mod$beta.min[1]
## -----------------------------------------------------------------------------
#alpha2
mod$beta.min[2]
## ----variable selection, figures-side, fig.show="hold", out.width="50%",echo=FALSE,fig.cap="\\label{fig:fig1}Left: Identified prognostic biomarkers. Right: Identified predictive biomarkers."----
beta_min <- mod$beta.min[-c(1,2)]
df_beta <- data.frame(beta_est=beta_min, Status = ifelse(c(beta1, beta2-beta1)==0, "non-active", "active"))
df_prog <- data.frame(beta_est=beta_min[1:p], Status = ifelse(beta1==0, "false positive", "true prognostic"), index=c(1:p))
df_pred <- data.frame(beta_est=beta_min[(p+1):(2*p)], Status = ifelse(c(beta2-beta1)==0, "false positive", "true predictive"), index=c(1:p))
df_plot_prog <- df_prog[which(df_prog$beta_est!=0), ]
df_plot_pred <- df_pred[which(df_pred$beta_est!=0), ]
ggplot2::ggplot(data=df_plot_prog, mapping=aes(y=beta_est, x=index, color=Status))+geom_point()+
theme_bw()+ylab("Estimated coefficients")+xlab("Indices of selected variables")
ggplot2::ggplot(data=df_plot_pred, mapping=aes(y=beta_est, x=index, color=Status))+geom_point()+
theme_bw()+ylab("Estimated coefficients")+xlab("Indices of selected variables")
ggplot2::ggplot(data=df_plot_prog, mapping=aes(y=beta_est, x=index, color=Status))+geom_point()+
theme_bw()+ylab("Estimated coefficients")+xlab("Indices of selected variables")
ggplot2::ggplot(data=df_plot_pred, mapping=aes(y=beta_est, x=index, color=Status))+geom_point()+
theme_bw()+ylab("Estimated coefficients")+xlab("Indices of selected variables")
## -----------------------------------------------------------------------------
which(beta_min[1:p]!=0)
## -----------------------------------------------------------------------------
which(beta_min[(p+1):(2*p)]!=0)
predict(mod)
## ----WLasso model, warning = FALSE, message = FALSE---------------------------
mod <- ProgPredLasso(X1 = X_bm[1:n1, ], X2 = X_bm[(n1+1):n, ], Y = Y, cor_matrix = Sigma_est)
install.packages("WLogit")
library(WLogit)
gc()
library(WLogit)
library(tibble)
library(ggplot2)
set.seed(123456)
## ----generate Sigma-----------------------------------------------------------
p <- 500 # number of variables
d <- 10 # number of actives
n <- 100 # number of samples
actives <- c(1:d)
nonacts <- c(1:p)[-actives]
Sigma <- matrix(0, p, p)
Sigma[actives, actives] <- 0.3
Sigma[-actives, actives] <- 0.5
Sigma[actives, -actives] <- 0.5
Sigma[-actives, -actives] <- 0.7
diag(Sigma) <- rep(1,p)
View(Sigma)
## ---- echo=FALSE--------------------------------------------------------------
data(X)
data(y)
y
View(X)
data(beta)
beta
rep(0,p)
actives
beta
## ----WLogit model, eval=FALSE-------------------------------------------------
mod <- WhiteningLogit(X = X, y = y)
## ---- echo=FALSE--------------------------------------------------------------
data(test)
View(test)
mod <- test
## ----beta---------------------------------------------------------------------
beta_min <- mod$beta.min
head(beta_min)
## ----variable selection,fig.width=4,fig.height=3------------------------------
beta_min <- mod$beta.min
df_beta <- data.frame(beta_est=beta_min, Status = ifelse(beta==0, "non-active", "active"))
View(df_beta)
df_plot <- df_beta[which(beta_min!=0), ]
df_plot$index <- which(beta_min!=0)
ggplot2::ggplot(data=df_plot, mapping=aes(y=beta_est, x=index, color=Status))+geom_point()+
theme_bw()+ylab("Estimated coefficients")+xlab("Indices of selected variables")
## ----lasso--------------------------------------------------------------------
library(glmnet)
cvfit = cv.glmnet(X, y, family = "binomial", type.measure = "class", intercept=FALSE)
## ----res lasso----------------------------------------------------------------
beta_lasso <- coef(cvfit, s = "lambda.min")
head(beta_lasso)
## ----lasso selection,fig.width=4,fig.height=3---------------------------------
beta_lasso <- as.vector(beta_lasso)[-1]
df_beta <- data.frame(beta_est=beta_lasso, Status = ifelse(beta==0, "non-active", "active"))
df_plot <- df_beta[which(beta_lasso!=0), ]
df_plot$index <- which(beta_lasso!=0)
ggplot2::ggplot(data=df_plot, mapping=aes(y=beta_est, x=index, color=Status))+geom_point()+
theme_bw()+ylab("Estimated coefficients by glmnet")+xlab("Indices of selected variables")
beta_lasso
## ----WLogit model, eval=FALSE-------------------------------------------------
mod <- WhiteningLogit(X = X, y = y)
## ----beta---------------------------------------------------------------------
beta_min <- mod$beta.min
head(beta_min)
## ----variable selection,fig.width=4,fig.height=3------------------------------
beta_min <- mod$beta.min
df_beta <- data.frame(beta_est=beta_min, Status = ifelse(beta==0, "non-active", "active"))
df_plot <- df_beta[which(beta_min!=0), ]
df_plot$index <- which(beta_min!=0)
ggplot2::ggplot(data=df_plot, mapping=aes(y=beta_est, x=index, color=Status))+geom_point()+
theme_bw()+ylab("Estimated coefficients")+xlab("Indices of selected variables")
ggplot2::ggplot(data=df_plot, mapping=aes(y=beta_est, x=index, color=Status))+geom_point()+
theme_bw()+ylab("Estimated coefficients by glmnet")+xlab("Indices of selected variables")
WhiteningLogit
## ---- echo=FALSE--------------------------------------------------------------
data(test)
mod <- test
## ----beta---------------------------------------------------------------------
beta_min <- mod$beta.min
head(beta_min)
## ----variable selection,fig.width=4,fig.height=3------------------------------
beta_min <- mod$beta.min
df_beta <- data.frame(beta_est=beta_min, Status = ifelse(beta==0, "non-active", "active"))
df_plot <- df_beta[which(beta_min!=0), ]
df_plot$index <- which(beta_min!=0)
ggplot2::ggplot(data=df_plot, mapping=aes(y=beta_est, x=index, color=Status))+geom_point()+
theme_bw()+ylab("Estimated coefficients")+xlab("Indices of selected variables")
c(F,F)||F
F||F
F||T
T||T
T||F
F|F
F|T
T|F
T|T
a <- CalculPx(X, beta_min)
a <- round(CalculPx(X, beta_min))
table(a,y)
## ----WLogit model, eval=FALSE-------------------------------------------------
mod <- WhiteningLogit(X = X, y = y)
## ----beta---------------------------------------------------------------------
beta_min <- mod$beta.min
head(beta_min)
## ----variable selection,fig.width=4,fig.height=3------------------------------
beta_min <- mod$beta.min
a <- round(CalculPx(X, beta_min))
table(a,y)
a <- round(CalculPx(X+1, beta_min))
table(a,y)
citation()
BiocManager::install("MLSeq")
library(MLSeq)
printAvailableMethods()
## ----knitr_options, echo=FALSE, results="hide", warning=FALSE-----------------
library(knitr)
opts_chunk$set(tidy = FALSE, dev = "pdf", fig.show = "hide", message = FALSE, fig.align = "center", cache = FALSE)
## ----load_packages, echo=FALSE, results="hide", warning=FALSE-----------------
library(MLSeq)
library(DESeq2)
library(edgeR)
library(VennDiagram)
library(pamr)
library(caret)
## ----file_path_cervical-------------------------------------------------------
filepath <- system.file("extdata/cervical.txt", package = "MLSeq")
## ----read_cervical_data-------------------------------------------------------
cervical <- read.table(filepath, header=TRUE)
View(cervical)
## ----head_cervical------------------------------------------------------------
head(cervical[ ,1:10]) # Mapped counts for first 6 features of 10 subjects.
## ----define_class_labels------------------------------------------------------
class <- DataFrame(condition = factor(rep(c("N","T"), c(29, 29))))
View(class)
class
## ----data_splitting-----------------------------------------------------------
library(DESeq2)
set.seed(2128)
# We do not perform a differential expression analysis to select differentially
# expressed genes. However, in practice, DE analysis might be performed before
# fitting classifiers. Here, we selected top 100 features having the highest
# gene-wise variances in order to decrease computational cost.
vars <- sort(apply(cervical, 1, var, na.rm = TRUE), decreasing = TRUE)
data <- cervical[names(vars)[1:100], ]
nTest <- ceiling(ncol(data) * 0.3)
ind <- sample(ncol(data), nTest, FALSE)
# Minimum count is set to 1 in order to prevent 0 division problem within
# classification models.
data.train <- as.matrix(data[ ,-ind] + 1)
data.test <- as.matrix(data[ ,ind] + 1)
classtr <- DataFrame(condition = class[-ind, ])
classts <- DataFrame(condition = class[ind, ])
## ----DESeqDataSets------------------------------------------------------------
data.trainS4 = DESeqDataSetFromMatrix(countData = data.train, colData = classtr,
design = formula(~condition))
data.testS4 = DESeqDataSetFromMatrix(countData = data.test, colData = classts,
design = formula(~condition))
## ----Optimizing_model_parameters_example, eval = TRUE, echo = TRUE------------
set.seed(2128)
# Support vector machines with radial basis function kernel
fit.svm <- classify(data = data.trainS4, method = "svmRadial",
preProcessing = "deseq-vst", ref = "T", tuneLength = 10,
control = trainControl(method = "repeatedcv", number = 5,
repeats = 10, classProbs = TRUE))
show(fit.svm)
## ----fitted_model_svm---------------------------------------------------------
trained(fit.svm)
## ----eval = FALSE-------------------------------------------------------------
plot(fit.svm)
## ----fitted_model_svm_figure, echo = FALSE, results='hide'--------------------
cairo_pdf(filename = "fitted_model_svm_figure.pdf", height = 5.5)
plot(fit.svm)
dev.off()
## ----echo = FALSE-------------------------------------------------------------
# Define control list
ctrl.voomDLDA <- voomControl(method = "repeatedcv", number = 5, repeats = 1,
tuneLength = 10)
# Voom-based diagonal linear discriminant analysis
fit.voomDLDA <- classify(data = data.trainS4, method = "voomDLDA",
normalize = "deseq", ref = "T", control = ctrl.voomDLDA)
## -----------------------------------------------------------------------------
trained(fit.voomDLDA)
## -----------------------------------------------------------------------------
#Predicted class labels
pred.svm <- predict(fit.svm, data.testS4)
pred.svm
## -----------------------------------------------------------------------------
pred.svm <- relevel(pred.svm, ref = "T")
actual <- relevel(classts$condition, ref = "T")
tbl <- table(Predicted = pred.svm, Actual = actual)
confusionMatrix(tbl, positive = "T")
## ----results='hide', message=FALSE--------------------------------------------
set.seed(2128)
# Define control lists.
ctrl.continuous <- trainControl(method = "repeatedcv", number = 5, repeats = 10)
ctrl.discrete <- discreteControl(method = "repeatedcv", number = 5, repeats = 10,
tuneLength = 10)
ctrl.voom <- voomControl(method = "repeatedcv", number = 5, repeats = 10,
tuneLength = 10)
# 1. Continuous classifiers, SVM and NSC
fit.svm <- classify(data = data.trainS4, method = "svmRadial",
preProcessing = "deseq-vst", ref = "T", tuneLength = 10,
control = ctrl.continuous)
fit.NSC <- classify(data = data.trainS4, method = "pam",
preProcessing = "deseq-vst", ref = "T", tuneLength = 10,
control = ctrl.continuous)
# 2. Discrete classifiers
fit.plda <- classify(data = data.trainS4, method = "PLDA", normalize = "deseq",
ref = "T", control = ctrl.discrete)
fit.plda2 <- classify(data = data.trainS4, method = "PLDA2", normalize = "deseq",
ref = "T", control = ctrl.discrete)
fit.nblda <- classify(data = data.trainS4, method = "NBLDA", normalize = "deseq",
ref = "T", control = ctrl.discrete)
# 3. voom-based classifiers
fit.voomDLDA <- classify(data = data.trainS4, method = "voomDLDA",
normalize = "deseq", ref = "T", control = ctrl.voom)
fit.voomNSC <- classify(data = data.trainS4, method = "voomNSC",
normalize = "deseq", ref = "T", control = ctrl.voom)
# 4. Predictions
pred.svm <- predict(fit.svm, data.testS4)
pred.NSC <- predict(fit.NSC, data.testS4)
## ----echo = FALSE, results='asis', message=FALSE------------------------------
library(xtable)
pred.svm <- predict(fit.svm, data.testS4)
pred.NSC <- predict(fit.NSC, data.testS4)
pred.plda <- predict(fit.plda, data.testS4)
pred.nblda <- predict(fit.nblda, data.testS4)
pred.voomDLDA <- predict(fit.voomDLDA, data.testS4)
pred.voomNSC <- predict(fit.voomNSC, data.testS4)
actual <- data.testS4$condition
nn <- length(actual)
diag.svm <- sum(diag(table(pred.svm, actual)))
diag.NSC <- sum(diag(table(pred.NSC, actual)))
diag.plda <- sum(diag(table(pred.plda, actual)))
diag.nblda <- sum(diag(table(pred.nblda, actual)))
diag.voomDLDA <- sum(diag(table(pred.voomDLDA, actual)))
diag.voomNSC <- sum(diag(table(pred.voomNSC, actual)))
acc <- c(diag.svm, diag.NSC, diag.plda, diag.nblda, diag.voomDLDA, diag.voomNSC) / nn
sparsity <- c(NA, trained(fit.NSC)$finalModel$nonzero/nrow(data.testS4),
length(selectedGenes(fit.plda))/nrow(data.testS4), NA, NA,
length(selectedGenes(fit.voomNSC))/nrow(data.testS4))
tbl <- data.frame(Classifier = c("SVM", "NSC", "PLDA (Transformed)", "NBLDA", "voomDLDA", "voomNSC"), Accuracy = acc, Sparsity = sparsity)
xtbl <- xtable(tbl, caption = "Classification results for cervical data.", label = "tbl:accRes", align = "lp{4cm}p{2cm}c")
digits(xtbl) <- c(0, 0, 3, 3)
print.xtable(xtbl, caption.placement = "top", include.rownames = FALSE, booktabs = TRUE)
## ----echo = FALSE-------------------------------------------------------------
best_in_accuracy <- as.character(tbl$Classifier[which(acc == max(acc, na.rm = TRUE))])
best_in_acc_text <- paste("\\textbf{", best_in_accuracy, "}", sep = "")
if (length(best_in_accuracy) >= 2){
best_in_acc_text <- paste(paste(best_in_acc_text[-length(best_in_acc_text)], collapse = ", "), best_in_acc_text[length(best_in_acc_text)], sep = " and ")
}
best_in_sparsity <- as.character(tbl$Classifier[which(sparsity == min(sparsity, na.rm = TRUE))])
best_in_sparsity_text <- paste("\\textbf{", best_in_sparsity, "}", sep = "")
if (length(best_in_sparsity) >= 2){
best_in_sparsity_text <- paste(paste(best_in_sparsity_text[-length(best_in_sparsity_text)], collapse = ", "), best_in_sparsity_text[length(best_in_sparsity_text)], sep = " and ")
}
## -----------------------------------------------------------------------------
selectedGenes(fit.voomNSC)
## ----all_common_features, echo = FALSE----------------------------------------
pam.final <- trained(fit.NSC)$finalModel   ## 'pamrtrained' object.
geneIdx <- pamr:::pamr.predict(pam.final, pam.final$xData, threshold = pam.final$threshold, type = "nonzero")
genes.pam <- colnames(pam.final$xData)[geneIdx]
genes.plda <- selectedGenes(fit.plda)
genes.plda2 <- selectedGenes(fit.plda2)
genes.vnsc <- selectedGenes(fit.voomNSC)
tmp.list <- list(genes.pam, genes.plda, genes.plda2, genes.vnsc)
nn <- c(length(genes.pam), length(genes.plda), length(genes.plda2), length(genes.vnsc))
ooo <- order(nn, decreasing = TRUE)
tmp.list <- tmp.list[ooo]
common <- tmp.list[[1]]
for (i in 2:(length(tmp.list))){
tmp2 <- tmp.list[[i]]
tmp <- common[common %in% tmp2]
common <- tmp
}
## ----venn_diagram, echo = FALSE-----------------------------------------------
venn.plot <- venn.diagram(
x = list(voomNSC = genes.vnsc, NSC = genes.pam, PLDA = genes.plda, PLDA2 = genes.plda2),
height = 1200, width = 1200,
resolution = 200,
filename = "Selected_features.png", imagetype = "png",
col = "black",
fill = c("khaki1", "skyblue", "tomato3", "darkolivegreen3"),
alpha = 0.50,
cat.cex = 1.2,
cex = 1.5,
cat.fontface = "bold"
)
## -----------------------------------------------------------------------------
set.seed(2128)
ctrl <- discreteControl(method = "repeatedcv", number = 5, repeats = 2,
tuneLength = 10)
# PLDA without power transformation
fit <- classify(data = data.trainS4, method = "PLDA", normalize = "deseq",
ref = "T", control = ctrl)
show(fit)
## -----------------------------------------------------------------------------
method(fit) <- "PLDA2"
show(fit)
## -----------------------------------------------------------------------------
ref(fit) <- "N"
normalization(fit) <- "TMM"
metaData(fit)
## -----------------------------------------------------------------------------
fit <- update(fit)
show(fit)
## ----echo = FALSE, message=FALSE, error=TRUE----------------------------------
method(fit) <- "rpart"
tmp <- try(update(fit))
## -----------------------------------------------------------------------------
control(fit) <- trainControl(method = "repeatedcv", number = 5, repeats = 2)
# 'normalize' is not valid for continuous classifiers. We use 'preProcessing'
# rather than 'normalize'.
preProcessing(fit) <- "tmm-logcpm"
fit <- update(fit)
show(fit)
## ----session_info-------------------------------------------------------------
sessionInfo()
setwd("/Users/giorgiomontesi/Desktop/Universita_di_Siena/A_PhD_Project/Biomarker_Prediction/ensembleBP/Codes")
library(ggplot2)
df1 <- read.csv2(paste0("../Results/AccuracyTable_1.csv"))
df2 <- read.csv2(paste0("../Results/AccuracyTable_2.csv"))
df3 <- read.csv2(paste0("../Results/AccuracyTable_3.csv"))
df4 <- read.csv2(paste0("../Results/AccuracyTable_4.csv"))
df5 <- read.csv2(paste0("../Results/AccuracyTable_5.csv"))
df6 <- read.csv2(paste0("../Results/AccuracyTable_6.csv"))
df7 <- read.csv2(paste0("../Results/AccuracyTable_7.csv"))
df8 <- read.csv2(paste0("../Results/AccuracyTable_8.csv"))
df9 <- read.csv2(paste0("../Results/AccuracyTable_9.csv"))
df10 <- read.csv2(paste0("../Results/AccuracyTable_10.csv"))
df1$Group <- c(rep("SVM-based",each=3), rep("voom-based",each=3),
rep("LDA-based",each=4), #rep("NNet-based",each=2),
rep("Tree-based",each=4), rep("Bagged",each=3),
rep("Boosted",each=3), rep("PLS-based",each=3))
df2$Group <- c(rep("SVM-based",each=3), rep("voom-based",each=3),
rep("LDA-based",each=4), #rep("NNet-based",each=2),
rep("Tree-based",each=4), rep("Bagged",each=3),
rep("Boosted",each=3), rep("PLS-based",each=3))
df3$Group <- c(rep("SVM-based",each=3), rep("voom-based",each=3),
rep("LDA-based",each=4), #rep("NNet-based",each=2),
rep("Tree-based",each=4), rep("Bagged",each=3),
rep("Boosted",each=3), rep("PLS-based",each=3))
df4$Group <- c(rep("SVM-based",each=3), rep("voom-based",each=3),
rep("LDA-based",each=4), #rep("NNet-based",each=2),
rep("Tree-based",each=4), rep("Bagged",each=3),
rep("Boosted",each=3), rep("PLS-based",each=3))
df5$Group <- c(rep("SVM-based",each=3), rep("voom-based",each=3),
rep("LDA-based",each=4), #rep("NNet-based",each=2),
rep("Tree-based",each=4), rep("Bagged",each=3),
rep("Boosted",each=3), rep("PLS-based",each=3))
df6$Group <- c(rep("SVM-based",each=3), rep("voom-based",each=3),
rep("LDA-based",each=4), #rep("NNet-based",each=2),
rep("Tree-based",each=4), rep("Bagged",each=3),
rep("Boosted",each=3), rep("PLS-based",each=3))
df7$Group <- c(rep("SVM-based",each=3), rep("voom-based",each=3),
rep("LDA-based",each=4), #rep("NNet-based",each=2),
rep("Tree-based",each=4), rep("Bagged",each=3),
rep("Boosted",each=3), rep("PLS-based",each=3))
df8$Group <- c(rep("SVM-based",each=3), rep("voom-based",each=3),
rep("LDA-based",each=4), #rep("NNet-based",each=2),
rep("Tree-based",each=4), rep("Bagged",each=3),
rep("Boosted",each=3), rep("PLS-based",each=3))
df9$Group <- c(rep("SVM-based",each=3), rep("voom-based",each=3),
rep("LDA-based",each=4), #rep("NNet-based",each=2),
rep("Tree-based",each=4), rep("Bagged",each=3),
rep("Boosted",each=3), rep("PLS-based",each=3))
df10$Group <- c(rep("SVM-based",each=3), rep("voom-based",each=3),
rep("LDA-based",each=4), #rep("NNet-based",each=2),
rep("Tree-based",each=4), rep("Bagged",each=3),
rep("Boosted",each=3), rep("PLS-based",each=3))
df <- do.call("rbind", list(df1, df2, df3, df4, df5, df6, df7, df8, df9, df10))
ggplot(df, aes(x = as.factor(X), y = Accuracy, fill = as.factor(Group))) +
geom_boxplot() +
geom_point() +
scale_fill_brewer(palette = c("Paired")) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"))
ggplot(df, aes(x = as.factor(X), y = Precision, fill = as.factor(Group))) +
geom_boxplot() +
geom_point() +
scale_fill_brewer(palette = c("Paired")) +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"))
ggplot(df, aes(x = as.factor(X), y = Recall, fill = as.factor(Group))) +
geom_boxplot() +
geom_point() +
scale_fill_brewer(palette = c("Paired")) +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"))
ggplot(df, aes(x = as.factor(X), y = Balanced.Accuracy, fill = as.factor(Group))) +
geom_boxplot() +
geom_point() +
scale_fill_brewer(palette = c("Paired")) +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"))
Upset_plot_no_merge <- function(lista_geni) {
# Carica il pacchetto tidyverse
library(tidyverse)
#Carico il pacchetto Upset
library(UpSetR)
# Estrai tutti i geni unici di tutti gli algoritmi
geni_unici <- sort(unique(unlist(lista_geni)))
# Crea un dataframe vuoto
df <- data.frame(RowName = names(lista_geni))
# Aggiungi colonne per ogni gene unico e assegna TRUE o FALSE in base alla presenza del gene
for (gene in geni_unici) {
df[[gene]] <- map_lgl(df$RowName, ~ gene %in% lista_geni[[.x]])
}
# Imposta i nomi delle righe uguali al nome dell'algoritmo
rownames(df) <- df$RowName
df$RowName <- NULL
df <- as.data.frame(t(df))
df <- as.data.frame(ifelse(df == "TRUE", 1, 0))
print(upset(df, nsets = ncol(df), nintersects = nrow(df),
color.pal = 1, sets.bar.color = "lightblue",
mb.ratio = c(0.4,0.6)))
}
a <- readRDS(file = "../Results/list_genes_1.rds")
Upset_plot_no_merge(a)
b <- readRDS(file = "../Results/list_genes_2.rds")
c <- readRDS(file = "../Results/list_genes_3.rds")
d <- readRDS(file = "../Results/list_genes_4.rds")
e <- readRDS(file = "../Results/list_genes_5.rds")
f <- readRDS(file = "../Results/list_genes_6.rds")
g <- readRDS(file = "../Results/list_genes_7.rds")
h <- readRDS(file = "../Results/list_genes_8.rds")
i <- readRDS(file = "../Results/list_genes_9.rds")
j <- readRDS(file = "../Results/list_genes_10.rds")
Upset_plot_no_merge(b)
Upset_plot_no_merge(c)
Upset_plot_no_merge(d)
Upset_plot_no_merge(e)
Upset_plot_no_merge(f)
Upset_plot_no_merge(g)
Upset_plot_no_merge(h)
Upset_plot_no_merge(i)
Upset_plot_no_merge(j)
