tblPLDA <- table(Predicted = pred.PLDA, Actual = actual)
PLDA.cm <- confusionMatrix(tblPLDA, positive = "D")
genes_PLDA_LDABased <- list(selectedGenes(fit.PLDA))
print("Fitting PLDA2")
set.seed(1510)
# PLDA2
fit.PLDA2 <- classify(data = data.trainS4, method = "PLDA2",
normalize = "deseq", ref = "D",
control = linearControl)
#Predicted class labels
pred.PLDA2 <- predict(fit.PLDA2, data.testS4)
pred.PLDA2 <- relevel(pred.PLDA2, ref = "D")
tblPLDA2 <- table(Predicted = pred.PLDA2, Actual = actual)
PLDA2.cm <- confusionMatrix(tblPLDA2, positive = "D")
genes_PLDA2_LDABased <- list(selectedGenes(fit.PLDA2))
print("Fitting NBLDA")
set.seed(1510)
# NBLDA
fit.NBLDA <- classify(data = data.trainS4, method = "NBLDA",
normalize = "deseq", ref = "D",
control = linearControl)
#Predicted class labels
pred.NBLDA <- predict(fit.NBLDA, data.testS4)
pred.NBLDA <- relevel(pred.NBLDA, ref = "D")
tblNBLDA <- table(Predicted = pred.NBLDA, Actual = actual)
NBLDA.cm <- confusionMatrix(tblNBLDA, positive = "D")
genes_NBLDA_LDABased <- list(selectedGenes(fit.NBLDA))
# La lista dei geni dovrebbe essere calcolabile in qualche modo da qui:
# ds <- fit.NBLDA@modelInfo@trainedModel@finalModel[["ds"]]
print("Successfully accomplished linear-based methods")
return(list(PLDA.cm, PLDA2.cm, NBLDA.cm,
genes_PLDA_LDABased, genes_PLDA2_LDABased, genes_NBLDA_LDABased))
}
#' @description Tests several sparse-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each sparse-based method
sparse.based <- function(data.trainS4, data.testS4, classts,
tL = 5, n = 5, r = 5){
library(sdwd)
library(sparseLDA)
library(spls)
# Define control function for all sparse.based classifiers
sparseControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
actual <- relevel(classts$condition, ref = "D")
print("Fitting sparseLDA")
set.seed(1510)
# Sparse linear discriminant analysis
fit.sparseLDA <- classify(data = data.trainS4, method = "sparseLDA",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = sparseControl)
#Predicted class labels
pred.sparseLDA <- predict(fit.sparseLDA, data.testS4)
pred.sparseLDA <- relevel(pred.sparseLDA, ref = "D")
tblsparseLDA <- table(Predicted = pred.sparseLDA, Actual = actual)
sparseLDA.cm <- confusionMatrix(tblsparseLDA, positive = "D")
# Compute important genes
genes_sparseLDA_LDAbased <- list(genes_sparseLDA_LDAbased = fit.sparseLDA@modelInfo@trainedModel[["finalModel"]][["varNames"]])
print("Successfully accomplished sparseLDA")
return(list(sparseLDA.cm, genes_sparseLDA_LDAbased))
}
#' @description Tests several tree-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each tree-based method
tree.based <- function(data.trainS4, data.testS4, classts,
tL = 5, n = 5, r = 5){
# Define control function for all NNet.based classifiers
treeControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE,
savePredictions = "all", returnData = T)
print("Fitting rpart")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.rpart <- classify(data = data.trainS4, method = "rpart",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
#Predicted class labels
pred.rpart <- predict(fit.rpart, data.testS4)
pred.rpart <- relevel(pred.rpart, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblrpart <- table(Predicted = pred.rpart, Actual = actual)
rpart.cm <- confusionMatrix(tblrpart, positive = "D")
genes_rpart_treeBased <- list(fit.rpart@modelInfo@trainedModel[["finalModel"]][["variable.importance"]])
print("Fitting cforest")
set.seed(1510)
# Sparse linear discriminant analysis
fit.cforest <- classify(data = data.trainS4, method = "cforest",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
#Predicted class labels
pred.cforest <- predict(fit.cforest, data.testS4)
pred.cforest <- relevel(pred.cforest, ref = "D")
tblcforest <- table(Predicted = pred.cforest, Actual = actual)
cforest.cm <- confusionMatrix(tblcforest, positive = "D")
# Compute elbow genes
coeff_cforest <- varImp(fit.cforest@modelInfo@trainedModel[["finalModel"]])$Overall
names(coeff_cforest) <- rownames(varImp(fit.cforest@modelInfo@trainedModel[["finalModel"]]))
genes_cforest_treeBased <- list(elbow_comp(coefficients = coeff_cforest))
print("Fitting ctree")
set.seed(1510)
# Sparse partial least squares
fit.ctree <- classify(data = data.trainS4, method = "ctree",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
#Predicted class labels
pred.ctree <- predict(fit.ctree, data.testS4)
pred.ctree <- relevel(pred.ctree, ref = "D")
tblctree <- table(Predicted = pred.ctree, Actual = actual)
ctree.cm <- confusionMatrix(tblctree, positive = "D")
# compute elbow genes
coeff_ctree <- varImp(fit.ctree@modelInfo@trainedModel)[["importance"]]$D
names(coeff_ctree) <- rownames(varImp(fit.ctree@modelInfo@trainedModel)[["importance"]])
genes_ctree_treeBased <- list(elbow_comp(coefficients = coeff_ctree))
# fit.ctree@modelInfo@trainedModel[["finalModel"]]@tree
print("Fitting rf")
set.seed(1510)
# Sparse partial least squares
fit.rf <- classify(data = data.trainS4, method = "rf",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = treeControl)
#Predicted class labels
pred.rf <- predict(fit.rf, data.testS4)
pred.rf <- relevel(pred.rf, ref = "D")
tblrf <- table(Predicted = pred.rf, Actual = actual)
rf.cm <- confusionMatrix(tblrf, positive = "D")
# Compute elbow genes
coeff_rf <- as.data.frame(fit.rf@modelInfo@trainedModel[["finalModel"]][["importance"]])$MeanDecreaseGini
names(coeff_rf) <- rownames(as.data.frame(fit.rf@modelInfo@trainedModel[["finalModel"]][["importance"]]))
genes_rf_treeBased <- list(elbow_comp(coefficients = coeff_rf))
print("Successfully accomplished tree-based methods")
return(list(rpart.cm, cforest.cm, ctree.cm, rf.cm,
genes_rpart_treeBased, genes_cforest_treeBased, genes_ctree_treeBased, genes_rf_treeBased))
}
#' @description Tests several bagging-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each bagging-based method
bagg.based <- function(data.trainS4, data.testS4, classts,
tL = 5, n = 5, r = 5){
library(adabag)
library(earth)
# Define control function for all bagg.based classifiers
baggControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE,
savePredictions = "all", returnData = T)
print("Fitting AdaBag")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.AdaBag <- classify(data = data.trainS4, method = "AdaBag",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
#Predicted class labels
pred.AdaBag <- predict(fit.AdaBag, data.testS4)
pred.AdaBag <- relevel(pred.AdaBag, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblAdaBag <- table(Predicted = pred.AdaBag, Actual = actual)
AdaBag.cm <- confusionMatrix(tblAdaBag, positive = "D")
genes_AdaBag_baggedBased <- list(fit.AdaBag@modelInfo@trainedModel[["finalModel"]][["importance"]])
print("Fitting treebag")
set.seed(1510)
# Sparse linear discriminant analysis
fit.treebag <- classify(data = data.trainS4, method = "treebag",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
#Predicted class labels
pred.treebag <- predict(fit.treebag, data.testS4)
pred.treebag <- relevel(pred.treebag, ref = "D")
tbltreebag <- table(Predicted = pred.treebag, Actual = actual)
treebag.cm <- confusionMatrix(tbltreebag, positive = "D")
# Compute elbow genes
coeff_treebag <- varImp(fit.treebag@modelInfo@trainedModel[["finalModel"]])$Overall
names(coeff_treebag) <- rownames(varImp(fit.treebag@modelInfo@trainedModel[["finalModel"]]))
genes_treebag_baggedBased <- list(elbow_comp(coefficients = coeff_treebag))
# fit.treebag@modelInfo@trainedModel[["finalModel"]][["mtrees"]]
print("Fitting bagFDA")
set.seed(1510)
# Sparse partial least squares
fit.bagFDA <- classify(data = data.trainS4, method = "bagFDA",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
#Predicted class labels
pred.bagFDA <- predict(fit.bagFDA, data.testS4)
pred.bagFDA <- relevel(pred.bagFDA, ref = "D")
tblbagFDA <- table(Predicted = pred.bagFDA, Actual = actual)
bagFDA.cm <- confusionMatrix(tblbagFDA, positive = "D")
print("Successfully accomplished bagging-based methods")
return(list(AdaBag.cm, treebag.cm, bagFDA.cm,
genes_AdaBag_baggedBased, genes_treebag_baggedBased))
}
#' @description Tests several boost-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each boost-based method
boost.based <- function(data.trainS4, data.testS4, classts,
tL = 5, n = 5, r = 5){
# Define control function for all boost.based classifiers
boostControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting gamboost")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.gamboost <- classify(data = data.trainS4, method = "gamboost",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = boostControl)
#Predicted class labels
pred.gamboost <- predict(fit.gamboost, data.testS4)
pred.gamboost <- relevel(pred.gamboost, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblgamboost <- table(Predicted = pred.gamboost, Actual = actual)
gamboost.cm <- confusionMatrix(tblgamboost, positive = "D")
genes_gamboost_boostBased <- list(names(coef(fit.gamboost@modelInfo@trainedModel[["finalModel"]])))
print("Fitting bstSm")
set.seed(1510)
# Sparse linear discriminant analysis
fit.bstSm <- classify(data = data.trainS4, method = "bstSm",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = boostControl)
#Predicted class labels
pred.bstSm <- predict(fit.bstSm, data.testS4)
pred.bstSm <- relevel(pred.bstSm, ref = "D")
tblbstSm <- table(Predicted = pred.bstSm, Actual = actual)
bstSm.cm <- confusionMatrix(tblbstSm, positive = "D")
genes_bstSm_boostBased <- list(fit.bstSm@modelInfo@trainedModel[["finalModel"]][["xNames"]][c(fit.bstSm@modelInfo@trainedModel[["finalModel"]][["xselect"]])])
print("Fitting bstTree")
set.seed(1510)
# Sparse partial least squares
fit.bstTree <- classify(data = data.trainS4, method = "bstTree",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = boostControl)
#Predicted class labels
pred.bstTree <- predict(fit.bstTree, data.testS4)
pred.bstTree <- relevel(pred.bstTree, ref = "D")
tblbstTree <- table(Predicted = pred.bstTree, Actual = actual)
bstTree.cm <- confusionMatrix(tblbstTree, positive = "D")
genes_bstTree_boostBased <- list(fit.bstTree@modelInfo@trainedModel[["finalModel"]][["xNames"]][c(fit.bstTree@modelInfo@trainedModel[["finalModel"]][["xselect"]])])
print("Successfully accomplished boost-based methods")
return(list(gamboost.cm, bstSm.cm, bstTree.cm,
genes_gamboost_boostBased, genes_bstSm_boostBased, genes_bstTree_boostBased))
}
#' @description Tests several pls-based classifiers
#' @param data.trainS4
#' @param data.testS4
#' @param classts
#' @param tL tune Length
#' @param n number of CV
#' @param r number of repeats for CV
#' @returns A list of Confusion Matrices one for each pls-based method
pls.based <- function(data.trainS4, data.testS4, classts,
tL = 5, n = 5, r = 5){
library(gpls)
# Define control function for all sparse.based classifiers
plsControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE)
print("Fitting gpls")
set.seed(1510)
# generalized partial least squares
fit.gpls <- classify(data = data.trainS4, method = "gpls",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = plsControl)
#Predicted class labels
pred.gpls <- predict(fit.gpls, data.testS4)
pred.gpls <- relevel(pred.gpls, ref = "D")
actual <- relevel(classts$condition, ref = "D")
tblgpls <- table(Predicted = pred.gpls, Actual = actual)
gpls.cm <- confusionMatrix(tblgpls, positive = "D")
# compute elbow genes
coeff_gpls <- abs(fit.gpls@modelInfo@trainedModel[["finalModel"]][["coefficients"]][-1])
genes_gpls_plsBased <- list(elbow_comp(coefficients = coeff_gpls))
print("Fitting pls")
set.seed(1510)
# partial least squares
fit.pls <- classify(data = data.trainS4, method = "pls",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = plsControl)
#Predicted class labels
pred.pls <- predict(fit.pls, data.testS4)
pred.pls <- relevel(pred.pls, ref = "D")
tblpls <- table(Predicted = pred.pls, Actual = actual)
pls.cm <- confusionMatrix(tblpls, positive = "D")
# compute elbow genes
coeff_pls <- abs(fit.pls@modelInfo@trainedModel[["finalModel"]][["coefficients"]][,1,])
genes_pls_plsBased <- list(elbow_comp(coefficients = coeff_pls))
print("Fitting SPLS")
set.seed(1510)
# Sparse partial least squares
fit.spls <- classify(data = data.trainS4, method = "spls",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = plsControl)
#Predicted class labels
pred.spls <- predict(fit.spls, data.testS4)
pred.spls <- relevel(pred.spls, ref = "D")
tblspls <- table(Predicted = pred.spls, Actual = actual)
spls.cm <- confusionMatrix(tblspls, positive = "D")
# compute elbow genes
coeff_spls <- abs(fit.spls@modelInfo@trainedModel[["finalModel"]][["normx"]])
genes_spls_plsBased <- list(elbow_comp(coefficients = coeff_spls))
print("Successfully accomplished pls-based methods")
return(list(gpls.cm, pls.cm, spls.cm,
genes_gpls_plsBased, genes_pls_plsBased, genes_spls_plsBased))
}
dfsImport <- dfs.import()
df <- dfsImport[[1]]
#df <- df[1:1500, ]
class <- dfsImport[[2]]
keep <- rowSums(df > 10) > round(ncol(df)/3)
df <- df[keep, ]
seed=123
crossVal.1layer <- function(seed, i, mincorr = 0.4){
tts <- trainTest.split(df, class, mincorr = mincorr, seed = seed)
data.trainS4 <- tts[[1]]
data.testS4 <- tts[[2]]
classts <- tts[[3]]
# mini-check per vedere se i geni filtati sono gli stessi
sum(rownames(assay(data.trainS4)) == rownames(assay(data.testS4)))
svm <- svm.based(data.trainS4, data.testS4, classts)
svmRadial <- svm[[1]]
svmPoly <- svm[[2]]
svmLinear <- svm[[3]]
genes_svmRadial_SVMBased <- svm[[4]]
genes_svmPoly_SVMBased <- svm[[5]]
genes_svmLinear_SVMBased <- svm[[6]]
voom <- voom.based(data.trainS4, data.testS4, classts)
voomDLDA <- voom[[1]]
voomDQDA <- voom[[2]]
voomNSC <- voom[[3]]
genes_voomDLDA_voomBased <- voom[[4]]
genes_voomDQDA_voomBased <- voom[[5]]
genes_voomNSC_voomBased <- voom[[6]]
lin <- linear.based(data.trainS4, data.testS4, classts)
PLDA <- lin[[1]]
PLDA2 <- lin[[2]]
NBLDA <- lin[[3]]
genes_PLDA_LDABased <- lin[[4]]
genes_PLDA2_LDABased <- lin[[5]]
sparse <- sparse.based(data.trainS4, data.testS4, classts) # <-- too slow!!
sparseLDA <- sparse[[1]]
genes_sparseLDA_LDABased <- sparse[[2]]
# net <- nnet.based(data.trainS4, data.testS4, classts) # <-- not properly working!!
# #nnet <- net[[1]]
# mlp <- net[[2]]
# mlpML <- net[[3]]
# #avNNet <- net[[4]]
tree <- tree.based(data.trainS4, data.testS4, classts)
rpart <- tree[[1]]
cforest <- tree[[2]]
ctree <- tree[[3]]
rf <- tree[[4]]
genes_rpart_treeBased <- tree[[5]]
genes_cforest_treeBased <- tree[[6]]
genes_ctree_treeBased <- tree[[7]]
genes_rf_treeBased <- tree[[8]]
bag <- bagg.based(data.trainS4, data.testS4, classts)
AdaBag <- bag[[1]]
treebag <- bag[[2]]
bagFDA <- bag[[3]]
genes_AdaBag_baggedBased <- bag[[4]]
genes_treebag_baggedBased <- bag[[5]]
bst <- boost.based(data.trainS4, data.testS4, classts)
gamboost <- bst[[1]]
bstSm <- bst[[2]]
bstTree <- bst[[3]]
genes_gamboost_boostBased <- bst[[4]]
genes_bstSm_boostBased <- bst[[5]]
genes_bstTree_boostBased <- bst[[6]]
partls <- pls.based(data.trainS4, data.testS4, classts)
gpls <- partls[[1]]
pls <- partls[[2]]
spls <- partls[[3]]
genes_gpls_plsBased <- partls[[4]]
genes_pls_plsBased <- partls[[5]]
genes_spls_plsBased <- partls[[6]]
acc.df <- data.frame(svmRadial = c(svmRadial$overall, svmRadial$byClass),
svmPoly = c(svmPoly$overall, svmPoly$byClass),
svmLinear = c(svmLinear$overall, svmLinear$byClass),
voomDLDA = c(voomDLDA$overall, voomDLDA$byClass),
voomDQDA = c(voomDQDA$overall, voomDQDA$byClass),
voomNSC = c(voomNSC$overall, voomNSC$byClass),
PLDA = c(PLDA$overall, PLDA$byClass),
PLDA2 = c(PLDA2$overall, PLDA2$byClass),
NBLDA = c(NBLDA$overall, NBLDA$byClass),
sparseLDA = c(sparseLDA$overall, sparseLDA$byClass),
# nnet = c(nnet$overall, nnet$byClass),
# mlp = c(mlp$overall, mlp$byClass),
# mlpML = c(mlpML$overall, mlpML$byClass),
# avNNet = c(avNNet$overall, avNNet$byClass),
rpart = c(rpart$overall, rpart$byClass),
cforest = c(cforest$overall, cforest$byClass),
ctree = c(ctree$overall, ctree$byClass),
rf = c(rf$overall, rf$byClass),
AdaBag = c(AdaBag$overall, AdaBag$byClass),
treebag = c(treebag$overall, treebag$byClass),
bagFDA = c(bagFDA$overall, bagFDA$byClass),
gamboost = c(gamboost$overall, gamboost$byClass),
bstSm = c(bstSm$overall, bstSm$byClass),
bstTree = c(bstTree$overall, bstTree$byClass),
gpls = c(gpls$overall, gpls$byClass),
pls = c(pls$overall, pls$byClass),
spls = c(spls$overall, spls$byClass))
#i=1
write.csv2(t(acc.df), paste0("../Results/AccuracyTable_",i,".csv"))
list_genes <- list(genes_svmRadial_SVMBased = genes_svmRadial_SVMBased,
genes_svmPoly_SVMBased = genes_svmPoly_SVMBased,
genes_svmLinear_SVMBased = genes_svmLinear_SVMBased,
genes_voomDLDA_voomBased = genes_voomDLDA_voomBased,
genes_voomDQDA_voomBased = genes_voomDQDA_voomBased,
genes_voomNSC_voomBased = genes_voomNSC_voomBased,
genes_PLDA_LDABased = genes_PLDA_LDABased,
genes_PLDA2_LDABased = genes_PLDA2_LDABased,
genes_sparseLDA_LDABased = genes_sparseLDA_LDABased,
genes_rpart_treeBased = genes_rpart_treeBased,
genes_cforest_treeBased = genes_cforest_treeBased,
genes_ctree_treeBased = genes_ctree_treeBased,
genes_rf_treeBased = genes_rf_treeBased,
genes_AdaBag_baggedBased = genes_AdaBag_baggedBased,
genes_treebag_baggedBased = genes_treebag_baggedBased,
genes_gamboost_boostBased = genes_gamboost_boostBased,
genes_bstSm_boostBased = genes_bstSm_boostBased,
genes_bstTree_boostBased = genes_bstTree_boostBased,
genes_gpls_plsBased = genes_gpls_plsBased,
genes_pls_plsBased = genes_pls_plsBased,
genes_spls_plsBased = genes_spls_plsBased)
saveRDS(list_genes, paste0("../Results/list_genes_",i,".rds"))
}
i = 1
crossVal.1layer(seed = i, i = i, mincorr = 0.4)
list_genes <- list(genes_svmRadial_SVMBased = genes_svmRadial_SVMBased,
genes_svmPoly_SVMBased = genes_svmPoly_SVMBased,
genes_svmLinear_SVMBased = genes_svmLinear_SVMBased,
genes_voomDLDA_voomBased = genes_voomDLDA_voomBased,
genes_voomDQDA_voomBased = genes_voomDQDA_voomBased,
genes_voomNSC_voomBased = genes_voomNSC_voomBased,
genes_PLDA_LDABased = genes_PLDA_LDABased,
genes_PLDA2_LDABased = genes_PLDA2_LDABased,
genes_sparseLDA_LDABased = genes_sparseLDA_LDABased,
genes_rpart_treeBased = genes_rpart_treeBased,
genes_cforest_treeBased = genes_cforest_treeBased,
genes_ctree_treeBased = genes_ctree_treeBased,
genes_rf_treeBased = genes_rf_treeBased,
genes_AdaBag_baggedBased = genes_AdaBag_baggedBased,
genes_treebag_baggedBased = genes_treebag_baggedBased,
genes_gamboost_boostBased = genes_gamboost_boostBased,
genes_bstSm_boostBased = genes_bstSm_boostBased,
genes_bstTree_boostBased = genes_bstTree_boostBased,
genes_gpls_plsBased = genes_gpls_plsBased,
genes_pls_plsBased = genes_pls_plsBased,
genes_spls_plsBased = genes_spls_plsBased)
a <- readRDS(file = "../Results/list_genes_1.rds")
View(a)
a[["genes_svmRadial_SVMBased"]]
a[["genes_svmPoly_SVMBased"]]
a[["genes_svmLinear_SVMBased"]]
a[["genes_voomDLDA_voomBased"]]
a[["genes_voomDQDA_voomBased"]]
a[["genes_voomNSC_voomBased"]]
a[["genes_PLDA_LDABased"]]
a[["genes_PLDA2_LDABased"]]
a[["genes_sparseLDA_LDABased"]]
a[["genes_rpart_treeBased"]]
a[["genes_cforest_treeBased"]]
a[["genes_ctree_treeBased"]]
a[["genes_rf_treeBased"]]
a[["genes_AdaBag_baggedBased"]]
a[["genes_treebag_baggedBased"]]
a[["genes_gamboost_boostBased"]]
a[["genes_bstSm_boostBased"]]
a[["genes_bstTree_boostBased"]]
a[["genes_gpls_plsBased"]]
a[["genes_pls_plsBased"]]
a[["genes_spls_plsBased"]]
View(a)
a[["genes_AdaBag_baggedBased"]][[1]]
a[["genes_AdaBag_baggedBased"]][[1]]>0
names(a[["genes_AdaBag_baggedBased"]][[1]]>0)
genes_voomDLDA_voomBased
genes_voomDLDA_voomBased[[1]]
a[["genes_AdaBag_baggedBased"]][[1]]
a[["genes_AdaBag_baggedBased"]][[1]]>0
a[["genes_AdaBag_baggedBased"]][[1]][a[["genes_AdaBag_baggedBased"]][[1]]>0]
names(a[["genes_AdaBag_baggedBased"]][[1]][a[["genes_AdaBag_baggedBased"]][[1]]>0])
tL = 5
n = 5
r = 5
# Define control function for all bagg.based classifiers
baggControl <- trainControl(method = "repeatedcv", number = n,
repeats = r, classProbs = TRUE,
savePredictions = "all", returnData = T)
print("Fitting AdaBag")
set.seed(1510)
# Sparse Distance Weighted Discrimination
fit.AdaBag <- classify(data = data.trainS4, method = "AdaBag",
preProcessing = "deseq-vst", ref = "D", tuneLength = tL,
control = baggControl)
b <- list(a=genes_cforest_treeBased[[1]], b = genes_rf_treeBased[[1]])
View(b)
